% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Model_TransformerModel.R
\name{Attention}
\alias{Attention}
\title{Attention Class}
\usage{
Attention()
}
\description{
Scaled dot-product attention mechanism.
}
\details{
Computes attention scores using query, key, and value matrices with
optional masking and dropout.
}
\keyword{internal}
