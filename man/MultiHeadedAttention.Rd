% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Model_TransformerModel.R
\name{MultiHeadedAttention}
\alias{MultiHeadedAttention}
\title{MultiHeadedAttention Class}
\usage{
MultiHeadedAttention(h, d_model, dropout = 0.1)
}
\arguments{
\item{h}{Number of attention heads}

\item{d_model}{Model dimensionality}

\item{dropout}{Dropout probability}
}
\description{
Multi-head attention mechanism for Transformer.
}
\keyword{internal}
