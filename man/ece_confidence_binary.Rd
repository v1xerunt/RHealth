% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Metrics_ECE_calibration.R
\name{ece_confidence_binary}
\alias{ece_confidence_binary}
\title{Expected Calibration Error for Binary Classification}
\usage{
ece_confidence_binary(prob, label, bins = 20L, adaptive = FALSE)
}
\arguments{
\item{prob}{Numeric vector \strong{or} two-column matrix \
containing predicted probabilities for the \emph{positive} class
(only the first column is used if a matrix is supplied).}

\item{label}{Numeric vector \strong{or} two-column matrix of true labels \
encoded as 0/1 (only the first column is used if a matrix is supplied).}

\item{bins}{Integer. Number of bins (default 20).}

\item{adaptive}{Logical. If \code{FALSE} (default) equal-width bins \
spanning \\(\link{0,1}\\) are used; if \code{TRUE} each bin contains the \
same number of samples (equal-size bins).}
}
\value{
A single numeric value â€“ the (adaptive) ECE.
}
\description{
Calculates \strong{Expected Calibration Error (ECE)} or \strong{Adaptive ECE}
for a binary classifier, reproducing the behaviour of
\code{pyhealth.metrics.calibration.ece_confidence_binary}.
}
\examples{
set.seed(1)
p  <- runif(1e4)          # predicted probabilities
y  <- rbinom(1e4, 1, 0.4) # ground-truth labels
ece_confidence_binary(p, y)             # standard ECE
ece_confidence_binary(p, y, adaptive=TRUE)  # adaptive ECE

}
