% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Model_TransformerModel.R
\name{Transformer}
\alias{Transformer}
\title{Transformer Model Class}
\usage{
Transformer(
  dataset = NULL,
  embedding_dim = 128,
  heads = 1,
  dropout = 0.5,
  num_layers = 1
)
}
\arguments{
\item{dataset}{A \code{SampleDataset} object providing input/output schema}

\item{embedding_dim}{Integer, embedding dimension. Default 128}

\item{heads}{Integer, number of attention heads. Default 1}

\item{dropout}{Numeric, dropout rate. Default 0.5}

\item{num_layers}{Integer, number of transformer blocks. Default 1}
}
\description{
Transformer-based model for healthcare prediction tasks.
Each feature is embedded and processed through independent Transformer layers.
The CLS embeddings are concatenated for final prediction.
}
\details{
\itemize{
\item Supports binary, multi-class, and regression tasks
\item Uses multi-head self-attention mechanisms
\item Each feature has its own Transformer encoder stack
\item CLS token embeddings are used for classification
}
}
